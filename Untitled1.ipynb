{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {}
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One scenario where you would want to determine if negative/positive words are being used is if you were analyzing comments on a product or a service. It would be an advantage for a company to analyze this because it would give them insights on what the company is doing correct or wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Day of Week                                        comments\n",
      "0      Monday                             Hello, how are you?\n",
      "1     Tuesday                            Today is a good day!\n",
      "2   Wednesday  It's my birthday so it's a really special day!\n",
      "3    Thursday       Today is neither a good day or a bad day!\n",
      "4      Friday                           I'm having a bad day.\n",
      "5    Saturday       There' s nothing special happening today.\n",
      "6      Sunday                      Today is a SUPER good day!\n",
      "\n",
      "Vectorized Words\n",
      "\n",
      "['are', 'bad', 'birthday', 'day', 'good', 'happening', 'having', 'hello', 'how', 'is', 'it', 'my', 'neither', 'nothing', 'or', 'really', 'so', 'special', 'super', 'there', 'today', 'you']\n",
      "\n",
      "Feature Words - Matrix View\n",
      "\n",
      "[[1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 2 1 0 0 0 1 1 1 0 0 0 0]\n",
      " [0 1 0 2 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0]\n",
      " [0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0]\n",
      " [0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0]]\n",
      "\n",
      "                                              text  Positive 1  Positive 2  \\\n",
      "0                             Hello, how are you?           0           0   \n",
      "1                            Today is a good day!           1           0   \n",
      "2  It's my birthday so it's a really special day!           0           1   \n",
      "3       Today is neither a good day or a bad day!           1           0   \n",
      "4                           I'm having a bad day.           0           0   \n",
      "5       There' s nothing special happening today.           0           1   \n",
      "6                      Today is a SUPER good day!           1           0   \n",
      "\n",
      "   Negative  Total Score  \n",
      "0         0            0  \n",
      "1         0            1  \n",
      "2         0            1  \n",
      "3         1            0  \n",
      "4         1           -1  \n",
      "5         0            1  \n",
      "6         0            1  \n",
      "\n",
      "Overall Score:   3\n"
     ]
    }
   ],
   "source": [
    "#Analyzing text for whether comments are positive or negative \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#Importing the csv file and creating a dataframe.\n",
    "dataframe = pd.read_csv('DailyComments.csv')\n",
    "\n",
    "#Displaying the datafram. \n",
    "print(dataframe) \n",
    "\n",
    "#Creating the corpus.\n",
    "corpus = dataframe['comments'] \n",
    "\n",
    "vectorizer = CountVectorizer() \n",
    "\n",
    "#Using the fit_transform to learn the vocabulary dictionary and return term-document matrix.\n",
    "X = vectorizer.fit_transform(corpus) \n",
    " \n",
    "print(\"\\nVectorized Words\\n\") \n",
    "\n",
    "#Listing the vectorized words.\n",
    "print(vectorizer.get_feature_names()) \n",
    "\n",
    "print(\"\\nFeature Words - Matrix View\\n\") \n",
    "\n",
    "#Displaying the term document matrix.\n",
    "print( X.toarray()) \n",
    "\n",
    "data = pd.DataFrame({'text' : corpus}) \n",
    "\n",
    "#Check for positive words and negative words \n",
    "data['Positive 1'] = df.text.str.count('good') \n",
    "data['Positive 2']= df.text.str.count('special') \n",
    "data['Negative'] = df.text.str.count('bad') \n",
    "data['Total Score'] = df.positive1 + df.positive2 - df.negative \n",
    "\n",
    " \n",
    "print(\"\\n\", data) \n",
    "\n",
    "#Summing the scores to obtain the overall score.\n",
    "Z = sum(df['TotScore']) \n",
    " \n",
    "print('\\nOverall Score:  ',Z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words1:   {'bmw', 'ford', 'chrysler', 'buick', 'dodge', 'chevy'}\n",
      "words2:   {'burger', 'bmw', 'ford', 'c', 'hotdog', 'd'}\n",
      "\n",
      "This is intersection: {'bmw', 'ford'}\n",
      "This is union: {'bmw', 'ford', 'burger', 'chrysler', 'buick', 'c', 'hotdog', 'd', 'dodge', 'chevy'}\n",
      "\n",
      "c Counter({'chrysler': 1, 'buick': 1, 'dodge': 1, 'chevy': 1, 'burger': 1, 'c': 1, 'hotdog': 1, 'd': 1})\n",
      "\n",
      "e and f\n",
      "\n",
      "e: Counter({'bmw': 1, 'ford': 1, 'chrysler': 1, 'buick': 1, 'dodge': 1, 'chevy': 1})\n",
      "f: Counter({'burger': 1, 'bmw': 1, 'ford': 1, 'c': 1, 'hotdog': 1, 'd': 1})\n",
      "\n",
      "n 8\n",
      "\n",
      "This is z 200.0\n"
     ]
    }
   ],
   "source": [
    "#jacard  - comparing words \n",
    "\n",
    "import collections \n",
    "def jaccard(a, b):\n",
    "\n",
    "#Creating the interecetion of a and b.\n",
    "    c = a.intersection(b) \n",
    "    print(\"\\nThis is intersection:\", c)\n",
    "    \n",
    "#Creating the union of a and b\n",
    "    d = a.union(b)\n",
    "    \n",
    "#Printing the union.\n",
    "    print(\"This is union:\", d)\n",
    "    \n",
    "#A counter is a container that stores elements a and b as dictionary keys, and their counts are stored as dictionary \n",
    "#values.\n",
    "    e = collections.Counter(a) \n",
    "    f = collections.Counter(b) \n",
    "    \n",
    "#Obtaining our dictionary of unique words.\n",
    "    c = (e - f) + (f - e) \n",
    "    print(\"\\nc\", c) \n",
    "    \n",
    "#Calculating the number of unique words.\n",
    "    n = sum(c.values())\n",
    "    print(\"\\ne and f\")\n",
    "    print(\"\\ne:\", e) \n",
    "    print(\"f:\", f) \n",
    "    print (\"\\nn\", n) \n",
    "    return float(len(c)) / (len(a) + len(b) - len(c)) \n",
    "\n",
    " \n",
    "#List of words used for computing the jaccard distance\n",
    "list1 = ['ford', 'chevy', 'bmw', 'dodge', 'chrysler', 'buick'] \n",
    "list2 = ['burger', 'hotdog', 'c', 'd', 'bmw', 'ford'] \n",
    "\n",
    "words1 = set(list1) \n",
    "words2 = set(list2) \n",
    "\n",
    "print(\"words1:  \", words1) \n",
    "print(\"words2:  \", words2) \n",
    "\n",
    "z = jaccard(words1, words2) \n",
    "\n",
    "print(\"\\nThis is z\", z*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selling 6\n",
      "listening 6\n",
      "complete 3\n",
      "casting 5\n",
      "cone 7\n",
      "lighting 6\n",
      "car 9\n",
      "cane 8\n",
      "walking 6\n"
     ]
    }
   ],
   "source": [
    "#Extra Credit: Calculating the edit distance in a word.\n",
    "\n",
    "import nltk \n",
    "\n",
    "#Take a list of words and compare how close a word is to the words in the list\n",
    "chosen_word = 'completing'\n",
    " \n",
    "list_words = ['selling', 'listening', 'complete', 'casting', 'cone', 'lighting', 'car', 'cane', 'walking']\n",
    " \n",
    "#For loop used for calculating the edit distance for each word. It will return the origninal word and what the\n",
    "#number of transformations made on the word.\n",
    "for word in list_words:\n",
    "    edit_distance = nltk.edit_distance(chosen_word, word)\n",
    "    print(word, edit_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
